{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9NO43ywK6gb",
        "outputId": "76f6cc40-c375-489f-e16a-1aadb39dde3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit pypdf langchain torch accelerate bitsandbytes transformers sentence_transformers faiss_cpu streamlit_chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmSGmV6GLWx3",
        "outputId": "bc75c33d-2bc5-428b-aa3b-929ec6d02e61"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ASUS\\Desktop\\flipkart\\Untitled16.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/flipkart/Untitled16.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstreamlit\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mst\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/flipkart/Untitled16.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstreamlit_chat\u001b[39;00m \u001b[39mimport\u001b[39;00m message\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/flipkart/Untitled16.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtempfile\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
            "    bitsandbytes from https://files.pythonhosted.org/packages/1e/2c/af22cd797fc368a9f098ed03015730e6568b884fe67f9940793d944a4b7b/bitsandbytes-0.41.1-py3-none-any.whl:\n",
            "        Expected sha256 b25228c27636367f222232ed4d1e1502eedd2064be215633734fb8ea0c1c65f4\n",
            "             Got        56fee0f62f408083a1e30c0bc6feeb8190dd473cede40809cc8349c9f3be9164\n",
            "\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
            "[notice] To update, run: C:\\Users\\ASUS\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from streamlit_chat import message\n",
        "import tempfile\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
        "\n",
        "#Loading the model\n",
        "def load_llm():\n",
        "    # Load the locally downloaded model here\n",
        "    llm = CTransformers(\n",
        "        model = \"llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
        "        model_type=\"llama\",\n",
        "        max_new_tokens = 512,\n",
        "        temperature = 0.5\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "st.title(\"Chat with CSV using Llama2 ü¶ôü¶ú\")\n",
        "st.markdown(\"<h3 style='text-align: center; color: white;'>Built by <a href='https://github.com/AIAnytime'>AI Anytime with ‚ù§Ô∏è </a></h3>\", unsafe_allow_html=True)\n",
        "\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload your Data\", type=\"csv\")\n",
        "\n",
        "if uploaded_file :\n",
        "   #use tempfile because CSVLoader only accepts a file_path\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
        "        tmp_file.write(uploaded_file.getvalue())\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    loader = CSVLoader(file_path=tmp_file_path, encoding=\"utf-8\", csv_args={\n",
        "                'delimiter': ','})\n",
        "    data = loader.load()\n",
        "    #st.json(data)\n",
        "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "                                       model_kwargs={'device': 'cpu'})\n",
        "\n",
        "    db = FAISS.from_documents(data, embeddings)\n",
        "    db.save_local(DB_FAISS_PATH)\n",
        "    llm = load_llm()\n",
        "    chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=db.as_retriever())\n",
        "\n",
        "    def conversational_chat(query):\n",
        "        result = chain({\"question\": query, \"chat_history\": st.session_state['history']})\n",
        "        st.session_state['history'].append((query, result[\"answer\"]))\n",
        "        return result[\"answer\"]\n",
        "\n",
        "    if 'history' not in st.session_state:\n",
        "        st.session_state['history'] = []\n",
        "\n",
        "    if 'generated' not in st.session_state:\n",
        "        st.session_state['generated'] = [\"Hello ! Ask me anything about \" + uploaded_file.name + \" ü§ó\"]\n",
        "\n",
        "    if 'past' not in st.session_state:\n",
        "        st.session_state['past'] = [\"Hey ! üëã\"]\n",
        "\n",
        "    #container for the chat history\n",
        "    response_container = st.container()\n",
        "    #container for the user's text input\n",
        "    container = st.container()\n",
        "\n",
        "    with container:\n",
        "        with st.form(key='my_form', clear_on_submit=True):\n",
        "\n",
        "            user_input = st.text_input(\"Query:\", placeholder=\"Talk to your csv data here (:\", key='input')\n",
        "            submit_button = st.form_submit_button(label='Send')\n",
        "\n",
        "        if submit_button and user_input:\n",
        "            output = conversational_chat(user_input)\n",
        "\n",
        "            st.session_state['past'].append(user_input)\n",
        "            st.session_state['generated'].append(output)\n",
        "\n",
        "    if st.session_state['generated']:\n",
        "        with response_container:\n",
        "            for i in range(len(st.session_state['generated'])):\n",
        "                message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user', avatar_style=\"big-smile\")\n",
        "                message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"thumbs\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DEkKJkAMUBy",
        "outputId": "25d19792-03fa-40b8-b670-6e6e2ce76758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.155.223.184:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py [ARGUMENTS]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
